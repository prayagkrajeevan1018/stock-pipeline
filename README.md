# ðŸ“ˆ Stock Market Data Pipeline

End-to-end batch data pipeline that ingests real stock market data, transforms it through a multi-layer warehouse, and serves analytics via a BI dashboard â€” fully orchestrated and containerized.

## Dashboard
![Dashboard](screenshots/dashboard.png)

## Architecture
```
yfinance API â†’ Python Ingestor â†’ Parquet Files â†’ DuckDB Warehouse â†’ Metabase Dashboard
                                                      â†‘
                                                 Airflow DAG
                                                 (orchestrates)
                                                      â†‘
                                                 dbt Models
                                             (raw â†’ staging â†’ marts)
```

## Tech Stack
| Layer | Tool |
|---|---|
| Ingestion | Python + yfinance |
| File Format | Apache Parquet |
| Orchestration | Apache Airflow |
| Warehouse | DuckDB |
| Transformation | dbt Core |
| Visualization | Metabase |
| Containers | Docker Compose |

## Pipeline Layers
- **Raw** â€” Parquet files loaded as-is into DuckDB
- **Staging** â€” Cleaned, typed, deduplicated via dbt
- **Marts** â€” Daily returns, volatility, moving averages (SMA7/30/90)

## Quick Start
```bash
# Start all services
docker-compose up -d

# Run ingestion
python ingestion/fetch_stocks.py
python ingestion/load_to_duckdb.py

# Run dbt
cd dbt_project
dbt run --profiles-dir .
dbt test --profiles-dir .
```

## Data Quality
20 automated dbt tests covering uniqueness, not-null checks, accepted values and custom SQL tests.

## Tickers Tracked
AAPL, MSFT, GOOGL, AMZN, META, TSLA, NVDA, JPM